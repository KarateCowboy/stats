#!/usr/bin/env node

/* This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this file,
 * You can obtain one at http://mozilla.org/MPL/2.0/. */

const async = require('async')
const amqp = require('amqplib/callback_api')
const elasticsearch = require('elasticsearch')
const uuid = require('uuid')
var path = require('path')

const pgc = require('../dist/pgc')
const mini = require('../dist/mini')

const reporter = require('../dist/reporter')

var jobName = path.basename(__filename)
var runInfo = reporter.startup(jobName)

// RabbitMQ connection parameters
const MQ_URL = process.env.RABBITMQ_BIGWIG_RX_URL || process.env.AMQP_URL || 'amqp://localhost:5672'
const MQ_QUEUE = process.env.MQ_QUEUE || 'crashes'

// ElasticSearch connection parameters
const ES_URL = process.env.SEARCHBOX_URL || 'localhost:9200'
const ES_INDEX = process.env.ES_INDEX || 'crashes'
const ES_TYPE = process.env.ES_TYPE || 'crash'

// Number of milliseconds for this process to run before timing out
const TIMEOUT = process.env.TIMEOUT || 60000

// Connect to Elastic Search at a host and port
const connectElasticSearch = function(cb) {
  console.log('Connecting to ElasticSearch at ' + ES_URL)
  var es = new elasticsearch.Client({
    host: ES_URL,
    log: null
  })
  cb(null, es)
}

// Connect to messaging system and return a communication channel
const connectAMQP = function(cb) {
  var amqpConnectionString = MQ_URL
  console.log('Connecting to AMQP server at ' + amqpConnectionString)
  amqp.connect(amqpConnectionString, (err, conn) => {
    if (err != null) {
      throw new Error(err)
    }
    console.log('AMQP connection established')
    var on_open = (err, ch) => {
      console.log(`AMQP connected to channel ${MQ_QUEUE}`)
      if (err != null) {
        throw new Error(err)
      }
      ch.assertQueue(MQ_QUEUE, {durable: true})
      cb(err, ch)
    }
    conn.createChannel(on_open)
  })
}

// This is triggered when connections to all resources are established
const resourcesReady = function (asyncError, resources) {
  if (asyncError) {
    throw new Error(asyncError.toString())
  }

  // Heroku processes are restarted every X minutes
  setInterval(() => {
    reporter.shutdown(runInfo, resources.pg, function () {
      process.exit()
    })
  }, TIMEOUT)

  // Write crash report meta data to Elastic Search (Kibana)
  const writeToElasticSearch = function (id, contents, cb) {
    resources.es.create({
      index: ES_INDEX,
      type: ES_TYPE,
      id: id,
      body: contents
    }, cb)
  }

  // Write crash report meta data to Postgres
  const writeToPostgres = function (id, contents, cb) {
    resources.pg.query(
      'INSERT INTO dtl.crashes (id, contents) VALUES($1, $2) ON CONFLICT (id) DO UPDATE SET contents = $2',
      [id, JSON.stringify(contents)],
      cb
    )
  }

  // Setup message throttling
  const CONSUMER_TAG = uuid.v4()
  const MAX_MESSAGES = parseInt(process.env.MAX_MESSAGES || 1)
  var msgCount = 0

  // Build a function capable of retrieving the crash report,
  // parsing and writing it to Postgres and ES
  function buildMessageHandler (msg, msgContents) {
    return function (cb) {
      console.log("Parsing crash report [" + msgContents._id + ']')
      // Read crash report from S3 and parse with minidump
      // (which handles Symbol substitution)
      mini.readAndParse(msgContents._id, (miniError, crashReport, metadata) => {
        crashReport = crashReport.toString()

        // install the parser minidump metadata into the crash report
        msgContents.metadata = metadata

        // Write the record to Postgres
        writeToPostgres(
          msgContents._id,
          msgContents,
          function(pgErr, results) {
            if (pgErr) {
              console.log(pgErr.toString())
            }
            console.log(`Written to Postgres [${msgContents._id}]`)

            // Write the record to Elastic Search
            writeToElasticSearch(
              msgContents._id,
              // We need to store the crash in a 'crash' attribute because
              // the _ver field collides with ElasticSearch
              { crash: msgContents },
              function (esErr, response) {
                if (esErr) {
                  console.log(esErr.toString())
                }
                console.log(`Indexed in Elastic Search [${msgContents._id}]`)
                // done, ack the message and callback
                resources.ch.ack(msg)
                // Ignore errors as they are often warnings about duplicates
                cb(null)
              }
            )
          })
      })
    }
  }

  // Start listening for messages
  console.log('All resources available. Processing a maximum of ' + MAX_MESSAGES + ' crash reports.')
  console.log('Reading messages from AMQP')

  var cancelled = false
  var funcs = []

  resources.ch.consume(MQ_QUEUE, (msg) => {
    var msgContents = JSON.parse(msg.content.toString())
    console.log("Handling message")

    msgCount += 1
    // Check here for max messages, if we are above the message threshold then fire the handlers
    if (msgCount > MAX_MESSAGES) {
      if (!cancelled) {
        resources.ch.cancel(CONSUMER_TAG, function() {
          console.log('Channel closed')

          // Execute all crash parser functions in series
          async.series(funcs, (seriesErr) => {
            if (seriesErr) {
              throw new Error(seriesErr)
            }
            console.log("Processing complete - exiting")
            // All done - close Postgres
            resources.pg.end()
            process.exit()
          })

        })
      }
      cancelled = true
      return
    }
    funcs.push(buildMessageHandler(msg, msgContents))
  }, { consumerTag: CONSUMER_TAG })
}

// Startup, connect to all required resources and start processing
async.parallel({
  es: connectElasticSearch,
  pg: pgc.setup,
  ch: connectAMQP
}, resourcesReady)
